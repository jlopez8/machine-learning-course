{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33fe75d",
   "metadata": {},
   "source": [
    "# Lesson 18 & 19 Neural Networks For Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c779a71",
   "metadata": {},
   "source": [
    "Neural networks or a biomimicry concept based on the brain. \n",
    "The brain uses neurons to determine \"activation\" states. \n",
    "If an activation state is reached in one neuron, information is passed to the next neuron. \n",
    "Neural networks look to copy this model.  \n",
    "\n",
    "<img src=\"neural_node.png\" width=\"500\">\n",
    "\n",
    "Each neuron has a **biased input**, $x_0$ with value 1. \n",
    "Neuron **weights** ($\\vec{w}_i$) are the <mark> model parameters </mark>.\n",
    "\n",
    "The output is obatined by applying some **activation function $g(x)$**:\n",
    "$$y_{output} = \\hat{y} = f(x, w) = g\\left( \\sum_{i=0}^{I} w_i x_i\\right)$$  \n",
    "\n",
    "## Feed-Forward Networks  \n",
    "\n",
    "Feedforward networks are organized as layers where each layer is **fully connected** to the next. They are directed acyclic graphs. \n",
    "\n",
    "- **Perceptron:** Single layer neural networks (perceptron): an input layer ->  output layer\n",
    "- **MLP / Multilayer Neural Networks** Input layer -> hidden layers, output layer. \n",
    "\n",
    "<mark> Some notes: </mark>  \n",
    "- The input layer has as many units are there are inputs in the problem. \n",
    "- The output layer has as many units as are needed for the problem. \n",
    "- Each hidden layer has multiple units (possibly a different number per layer). \n",
    "- Input of each unit are all the outputs of the units of the previous layer. \n",
    "\n",
    "<img src=\"multilayer_neural_network.png\" width=\"300\"> \n",
    "\n",
    "## Data  \n",
    "We will work with the energy data used previously to predict the power consumption based on several features. This data is a <mark> time-series</mark> dataset. We can check \"Lesson 16 - Support Vector Machines for Regression\" for the initial notes on the dataset. We don't need to repeat that here.  \n",
    "\n",
    "There are 19735 datapoints and  28 features + 1 output = 29. The output is the energy consumption column. This is represented in the 'Appliances' column.  \n",
    "\n",
    "Remember, since this is time series data, we will not do the traditional train-test-splitting we do for non-transient data. We can split it at a specific timepoint.  We will use this <mark> Time-series window </mark> approach. This creates a matrix of repetitive, broken-up chunks of data we use to separate our output information. This approach will produce a 3D matrix, because it splits according to: time and space. We only have 1 output, so this will be redundant\n",
    "\n",
    "<img src=\"sliding_window.png\" width=\"300\">  \n",
    "\n",
    "<mark> It is important  to normalize our data </mark> in this approach.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca426bc",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron Neural Network\n",
    "\n",
    "- MLP utilizes a supervised learning technique called back-propagation (calculus / diffeq based). \n",
    "- Except for input nodes, each node we have is a neuran that uses a **nonlinear activation function**.  \n",
    "- <mark> it can distinguish data that is not linearly separable </mark>  \n",
    "- <mark> MLP is a deep learning approach </mark>\n",
    "\n",
    "This mode receives multiple hyperparameters:   \n",
    "(these are stored in \"params\". Array values correspond to no. hidden layers.)  \n",
    "- `hidden_layer_sizes`: Number of hidden layers.\n",
    "- `activation`: Activation function. String values identifying predetermined functions. This may include \"RELU\", \"logistic\", etc...\n",
    "- `alpha`: Magnitude of coefficient of $L2$ loss function. \n",
    "- `momentum`: Similar to physics momentum. Update direction resists change when momentum is in effect. This has the effect of <mark> overshooting local minima</mark> because they are too shallow to stop a minimization algorithm unless a sufficiently low minima exists. IE <mark> only deep enough minima </mark> will stop this training momentum. \n",
    "- `learning_rate_init`: Step size control for weight updates. \n",
    "- `n_iter_no_change`: No. Iterations allowed during training while score is not improving. \n",
    "- `learning_rate`: Scheme for updating learning rate started by `learning_rate_init`. **Constant**: does not change from initial. **invscaling**: gradually decrease learning rate at each timestep using inverse scaling exponent. **adaptive**: keeps learning rate constant to `learning_rate_init` as long as training loss keeps decreasing. Once two consecutive epocs fail to decrease training loss by at least the tolerance of the optimization, or fails to increase validation score by at least tol if `early_stopping` is enabled, the current learning rate is cut by 5 (20%).\n",
    "\n",
    "\\begin{align}\n",
    "    \\text{RELU (rectified linear unit)} : \\ \\ f(x) = max(0, x) \\\\[0.5ex]\n",
    "    \\text{Logistic (sigmoid function)} : \\ \\ f(x) = 1 / (1 + exp(-x))\n",
    "\\end{align}  \n",
    "\n",
    "**note:** this learning_rate business is similar to an \"adaptive timestep\" scheme in CFD.  \n",
    "\n",
    "<mark> To solve </mark> we will use **BayesSearch cross validation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13fca4",
   "metadata": {},
   "source": [
    "# < START >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c367b5",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3aeb6f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jaimemerizalde/Desktop/Library\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425bf8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from Library import data\n",
    "\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fc340f",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ebf7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'Appliances', 'lights', 'T1', 'RH_1', 'T2', 'RH_2', 'T3',\n",
       "       'RH_3', 'T4', 'RH_4', 'T5', 'RH_5', 'T6', 'RH_6', 'T7', 'RH_7', 'T8',\n",
       "       'RH_8', 'T9', 'RH_9', 'T_out', 'Press_mm_hg', 'RH_out', 'Windspeed',\n",
       "       'Visibility', 'Tdewpoint', 'rv1', 'rv2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"Datasets/Energy.csv\"\n",
    "df = data.get_data(filename, index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ffe92d",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac3aa153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Appliances</th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>...</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19735</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "      <td>19735.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>11-01-2016 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>97.694958</td>\n",
       "      <td>3.801875</td>\n",
       "      <td>21.686571</td>\n",
       "      <td>40.259739</td>\n",
       "      <td>20.341219</td>\n",
       "      <td>40.420420</td>\n",
       "      <td>22.267611</td>\n",
       "      <td>39.242500</td>\n",
       "      <td>20.855335</td>\n",
       "      <td>...</td>\n",
       "      <td>19.485828</td>\n",
       "      <td>41.552401</td>\n",
       "      <td>7.412580</td>\n",
       "      <td>755.522602</td>\n",
       "      <td>79.750418</td>\n",
       "      <td>4.039752</td>\n",
       "      <td>38.330834</td>\n",
       "      <td>3.760995</td>\n",
       "      <td>24.988033</td>\n",
       "      <td>24.988033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>102.524891</td>\n",
       "      <td>7.935988</td>\n",
       "      <td>1.606066</td>\n",
       "      <td>3.979299</td>\n",
       "      <td>2.192974</td>\n",
       "      <td>4.069813</td>\n",
       "      <td>2.006111</td>\n",
       "      <td>3.254576</td>\n",
       "      <td>2.042884</td>\n",
       "      <td>...</td>\n",
       "      <td>2.014712</td>\n",
       "      <td>4.151497</td>\n",
       "      <td>5.318464</td>\n",
       "      <td>7.399441</td>\n",
       "      <td>14.901088</td>\n",
       "      <td>2.451221</td>\n",
       "      <td>11.794719</td>\n",
       "      <td>4.195248</td>\n",
       "      <td>14.496634</td>\n",
       "      <td>14.496634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.790000</td>\n",
       "      <td>27.023333</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>20.463333</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>28.766667</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.890000</td>\n",
       "      <td>29.166667</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>729.300000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-6.600000</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.005322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.760000</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>37.900000</td>\n",
       "      <td>20.790000</td>\n",
       "      <td>36.900000</td>\n",
       "      <td>19.530000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>750.933333</td>\n",
       "      <td>70.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>12.497889</td>\n",
       "      <td>12.497889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>39.656667</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>38.530000</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>19.390000</td>\n",
       "      <td>40.900000</td>\n",
       "      <td>6.920000</td>\n",
       "      <td>756.100000</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>24.897653</td>\n",
       "      <td>24.897653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>43.066667</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>43.260000</td>\n",
       "      <td>23.290000</td>\n",
       "      <td>41.760000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>44.338095</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>760.933333</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>37.583769</td>\n",
       "      <td>37.583769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>26.260000</td>\n",
       "      <td>63.360000</td>\n",
       "      <td>29.856667</td>\n",
       "      <td>56.026667</td>\n",
       "      <td>29.236000</td>\n",
       "      <td>50.163333</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>53.326667</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>772.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>49.996530</td>\n",
       "      <td>49.996530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date    Appliances        lights            T1  \\\n",
       "count              19735  19735.000000  19735.000000  19735.000000   \n",
       "unique             19735           NaN           NaN           NaN   \n",
       "top     11-01-2016 17:00           NaN           NaN           NaN   \n",
       "freq                   1           NaN           NaN           NaN   \n",
       "mean                 NaN     97.694958      3.801875     21.686571   \n",
       "std                  NaN    102.524891      7.935988      1.606066   \n",
       "min                  NaN     10.000000      0.000000     16.790000   \n",
       "25%                  NaN     50.000000      0.000000     20.760000   \n",
       "50%                  NaN     60.000000      0.000000     21.600000   \n",
       "75%                  NaN    100.000000      0.000000     22.600000   \n",
       "max                  NaN   1080.000000     70.000000     26.260000   \n",
       "\n",
       "                RH_1            T2          RH_2            T3          RH_3  \\\n",
       "count   19735.000000  19735.000000  19735.000000  19735.000000  19735.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean       40.259739     20.341219     40.420420     22.267611     39.242500   \n",
       "std         3.979299      2.192974      4.069813      2.006111      3.254576   \n",
       "min        27.023333     16.100000     20.463333     17.200000     28.766667   \n",
       "25%        37.333333     18.790000     37.900000     20.790000     36.900000   \n",
       "50%        39.656667     20.000000     40.500000     22.100000     38.530000   \n",
       "75%        43.066667     21.500000     43.260000     23.290000     41.760000   \n",
       "max        63.360000     29.856667     56.026667     29.236000     50.163333   \n",
       "\n",
       "                  T4  ...            T9          RH_9         T_out  \\\n",
       "count   19735.000000  ...  19735.000000  19735.000000  19735.000000   \n",
       "unique           NaN  ...           NaN           NaN           NaN   \n",
       "top              NaN  ...           NaN           NaN           NaN   \n",
       "freq             NaN  ...           NaN           NaN           NaN   \n",
       "mean       20.855335  ...     19.485828     41.552401      7.412580   \n",
       "std         2.042884  ...      2.014712      4.151497      5.318464   \n",
       "min        15.100000  ...     14.890000     29.166667     -5.000000   \n",
       "25%        19.530000  ...     18.000000     38.500000      3.670000   \n",
       "50%        20.666667  ...     19.390000     40.900000      6.920000   \n",
       "75%        22.100000  ...     20.600000     44.338095     10.400000   \n",
       "max        26.200000  ...     24.500000     53.326667     26.100000   \n",
       "\n",
       "         Press_mm_hg        RH_out     Windspeed    Visibility     Tdewpoint  \\\n",
       "count   19735.000000  19735.000000  19735.000000  19735.000000  19735.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean      755.522602     79.750418      4.039752     38.330834      3.760995   \n",
       "std         7.399441     14.901088      2.451221     11.794719      4.195248   \n",
       "min       729.300000     24.000000      0.000000      1.000000     -6.600000   \n",
       "25%       750.933333     70.333333      2.000000     29.000000      0.900000   \n",
       "50%       756.100000     83.666667      3.666667     40.000000      3.430000   \n",
       "75%       760.933333     91.666667      5.500000     40.000000      6.570000   \n",
       "max       772.300000    100.000000     14.000000     66.000000     15.500000   \n",
       "\n",
       "                 rv1           rv2  \n",
       "count   19735.000000  19735.000000  \n",
       "unique           NaN           NaN  \n",
       "top              NaN           NaN  \n",
       "freq             NaN           NaN  \n",
       "mean       24.988033     24.988033  \n",
       "std        14.496634     14.496634  \n",
       "min         0.005322      0.005322  \n",
       "25%        12.497889     12.497889  \n",
       "50%        24.897653     24.897653  \n",
       "75%        37.583769     37.583769  \n",
       "max        49.996530     49.996530  \n",
       "\n",
       "[11 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.columns\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86901560",
   "metadata": {},
   "source": [
    "# Partition Data Set / Train-Test-Split DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7b5ea3b",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Output Data\n",
    "energy = df.loc[:, \"Appliances\"]\n",
    "energy\n",
    "\n",
    "# Split Output Data\n",
    "e_train, e_test = energy.iloc[:12000], energy.iloc[12000:]\n",
    "\n",
    "# Data Scale\n",
    "scaler = MinMaxScaler()\n",
    "e_train_scaled = scaler.fit_transform(e_train.to_numpy().reshape(-1, 1))\n",
    "e_test_scaled = scaler.transform(e_test.to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Sliding Window\n",
    "## 4 predictors for 1 output in this case. \n",
    "## This will produce a window of shape 11996 x 1 x 5, which we don't need one column of.\n",
    "## That is why we use the squee method, to reduce this unnecessary complexity.\n",
    "## The last value in our sliding window is what we will consider the test value, and the\n",
    "## ones that came before our our training values.\n",
    "w = 4\n",
    "## Train\n",
    "window_train = sliding_window_view(e_train_scaled, w + 1, axis=0)\n",
    "window_train = window_train.squeeze()\n",
    "X_train_w = window_train[:, :-1]\n",
    "y_train_w = window_train[:, -1]\n",
    "\n",
    "## Test\n",
    "window_test = sliding_window_view(e_test_scaled, w + 1, axis=0)\n",
    "window_test = window_test.squeeze()\n",
    "X_test_w = window_test[:,:-1]\n",
    "y_test_w = window_test[:,-1]\n",
    "\n",
    "## Input data /parameters is split later during application of BayesSearch Cross Validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e1de73",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf20cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "params = {\n",
    "    \"hidden_layer_sizes\": [100, 200, 300], \n",
    "    \"activation\": [\"relu\", \"logistic\"], \n",
    "    \"alpha\": [0.0001, 0.001, 0.01], # L2\n",
    "    \"momentum\": [0.95, 0.90, 0.85], # local minima momentum \n",
    "    \"learning_rate_init\": [0.001, 0.01, 0.1], #step-size control for weight updates.\n",
    "    \"n_iter_no_change\": [30, 40, 50],  # No. Iterations allowed during training while score is not improving. \n",
    "    \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"], # scheme for changing the learning rate started by `learning_rate_init`\n",
    "}\n",
    "\n",
    "mlp = MLPRegressor(max_iter=100000, early_stopping=True, random_state=0)\n",
    "mlp_bs = BayesSearchCV(\n",
    "    mlp, params,\n",
    "    cv = TimeSeriesSplit(n_splits=5, gap=w + 1), \n",
    "    scoring=make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    n_iter=15, n_jobs=-1, refit=True, random_state=0, \n",
    "\n",
    ")\n",
    "mlp_bs.fit(X_train_w, y_train_w)\n",
    "\n",
    "with open(\"multilayer_perceptron_nerual_network_fit.pkl\", \"wb\") as file:\n",
    "    pickle.dump(mlp_bs, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
